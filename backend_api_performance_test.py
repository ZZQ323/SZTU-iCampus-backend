#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åç«¯APIæ€§èƒ½ä¸“é¡¹æµ‹è¯•
é‡ç‚¹æµ‹è¯•ï¼šäººå‘˜è¡¨æ ¼æŸ¥è¯¢ã€ç™»å½•è¿‡ç¨‹æ—¶é•¿ã€å„APIç«¯ç‚¹æ€§èƒ½

æ—¥æœŸï¼š2025-06-25
"""

import asyncio
import aiohttp
import time
import json
import statistics
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import random

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend_api_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BackendAPIPerformanceTester:
    """åç«¯APIä¸“é¡¹æ€§èƒ½æµ‹è¯•"""
    
    def __init__(self):
        self.backend_url = "http://127.0.0.1:8000"
        self.data_service_url = "http://127.0.0.1:8001"
        self.api_key = "sztu-data-service-key-2024"
        self.session = None
        self.test_accounts = []  # å­˜å‚¨æµ‹è¯•è´¦å·
        
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›å…¥"""
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        if self.session:
            await self.session.close()
    
    async def prepare_test_accounts(self) -> List[Dict[str, Any]]:
        """å‡†å¤‡æµ‹è¯•è´¦å· - ä½¿ç”¨æ•°æ®åº“ä¸­çš„çœŸå®è´¦å·"""
        # ç›´æ¥ä½¿ç”¨ä»æ•°æ®åº“æŸ¥è¯¢åˆ°çš„çœŸå®è´¦å·ä¿¡æ¯
        self.test_accounts = [
            # ç®¡ç†å‘˜è´¦å·
            {"login_id": "2025000001", "password": "Admin001HP1dbd10", "person_type": "admin", "name": "ä½•å¹³", "person_id": "P2025063441"},
            {"login_id": "2025000002", "password": "Admin002LGQ17e222", "person_type": "admin", "name": "æ¢å›½å¼º", "person_id": "P2025063442"},
            {"login_id": "2025000003", "password": "Admin003YGQf87252", "person_type": "admin", "name": "äºå›½å¼º", "person_id": "P2025063443"},
            {"login_id": "2025000004", "password": "Admin004LQfdc75c", "person_type": "admin", "name": "ç½—å¼º", "person_id": "P2025063444"},
            {"login_id": "2025000005", "password": "Admin005GJG074ca3", "person_type": "admin", "name": "éƒ­å»ºå›½", "person_id": "P2025063445"},
            
            # å­¦ç”Ÿè´¦å·
            {"login_id": "202100000001", "password": "000001Ty901StuwA", "person_type": "student", "name": "å”å‹‡", "person_id": "P2025000001"},
            {"login_id": "202100000002", "password": "000002Gw901StuK6", "person_type": "student", "name": "éƒ­æ–‡", "person_id": "P2025000002"},
            {"login_id": "202100000003", "password": "000003Zp901Stul1", "person_type": "student", "name": "å‘¨å¹³", "person_id": "P2025000003"},
            {"login_id": "202100000004", "password": "000004Hq901StuHz", "person_type": "student", "name": "é»„å¼º", "person_id": "P2025000004"},
            {"login_id": "202100000005", "password": "000005Xl901Stu1v", "person_type": "student", "name": "å¾ä¸½", "person_id": "P2025000005"},
            {"login_id": "202100000006", "password": "000006Sxl901StuO", "person_type": "student", "name": "å®‹ç§€å…°", "person_id": "P2025000006"},
            {"login_id": "202100000007", "password": "000007Lh901Stu7v", "person_type": "student", "name": "æ¢å", "person_id": "P2025000007"},
            {"login_id": "202100000008", "password": "000008Zx901StuEB", "person_type": "student", "name": "éƒ‘éœ", "person_id": "P2025000008"},
            {"login_id": "202100000009", "password": "000009Xg901StuFT", "person_type": "student", "name": "å¾åˆš", "person_id": "P2025000009"},
            {"login_id": "202100000010", "password": "000010Ly901Stu8k", "person_type": "student", "name": "æ—æ´‹", "person_id": "P2025000010"},
            
            # æ•™å¸ˆè´¦å·
            {"login_id": "2025001001", "password": "1001GaojSztu2024", "person_type": "teacher", "name": "é«˜å†›", "person_id": "P2025062401"},
            {"login_id": "2025001002", "password": "1002ChenSztu2024", "person_type": "teacher", "name": "é™ˆå»ºå", "person_id": "P2025062402"},
            {"login_id": "2025001003", "password": "1003SungSztu2024", "person_type": "teacher", "name": "å­™å›½å¼º", "person_id": "P2025062403"},
            {"login_id": "2025001004", "password": "1004XiaoSztu2024", "person_type": "teacher", "name": "è§æ°", "person_id": "P2025062404"},
            {"login_id": "2025001005", "password": "1005FengSztu2024", "person_type": "teacher", "name": "å†¯æ´‹", "person_id": "P2025062405"},
        ]
        
        logger.info(f"âœ… å‡†å¤‡äº† {len(self.test_accounts)} ä¸ªçœŸå®æµ‹è¯•è´¦å·")
        return self.test_accounts
    
    async def test_real_login_query_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•çœŸå®ç™»å½•éªŒè¯æŸ¥è¯¢æ€§èƒ½ - å®Œå…¨æ¨¡æ‹Ÿç™»å½•æ—¶çš„4è¡¨JOINæŸ¥è¯¢"""
        logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•çœŸå®ç™»å½•éªŒè¯æŸ¥è¯¢æ€§èƒ½...")
        
        # ç¡®ä¿æœ‰æµ‹è¯•è´¦å·
        if not self.test_accounts:
            await self.prepare_test_accounts()
        
        if not self.test_accounts:
            return {"error": "æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•è´¦å·"}
        
        results = []
        test_count = min(50, len(self.test_accounts))  # æµ‹è¯•50æ¬¡æˆ–æ‰€æœ‰è´¦å·
        
        for i in range(test_count):
            account = random.choice(self.test_accounts)
            
            try:
                # æ„å»ºä¸ç™»å½•æ—¶å®Œå…¨ç›¸åŒçš„æŸ¥è¯¢æ¡ä»¶
                auth_query_data = {
                    "login_id": account["login_id"],
                    "password": account["password"]
                }
                
                headers = {"X-API-Key": self.api_key, "Content-Type": "application/json"}
                start_time = time.time()
                
                # ç›´æ¥è°ƒç”¨data-serviceçš„auth/loginç«¯ç‚¹ï¼ˆä¸ç™»å½•é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
                async with self.session.post(
                    f"{self.data_service_url}/auth/login",
                    headers=headers,
                    json=auth_query_data
                ) as response:
                    end_time = time.time()
                    response_time = (end_time - start_time) * 1000
                    
                    if response.status == 200:
                        result_data = await response.json()
                        user_info = result_data.get("data", {}).get("user_info", {})
                        
                        # éªŒè¯è¿”å›çš„å®Œæ•´ä¿¡æ¯ï¼ˆæ¨¡æ‹ŸçœŸå®ç™»å½•éªŒè¯ï¼‰
                        expected_fields = [
                            "person_id", "person_type", "name", "phone", "email",
                            "academic_status", "employment_status", "college_name", 
                            "major_name", "class_name", "department_name"
                        ]
                        
                        field_count = sum(1 for field in expected_fields if user_info.get(field))
                        
                        results.append({
                            "response_time": response_time,
                            "status": "success",
                            "person_type": user_info.get("person_type", "unknown"),
                            "fields_returned": field_count,
                            "has_college_info": bool(user_info.get("college_name")),
                            "has_major_info": bool(user_info.get("major_name")),
                            "has_class_info": bool(user_info.get("class_name")),
                            "has_department_info": bool(user_info.get("department_name")),
                            "login_id": account["login_id"],
                            "response_size": len(json.dumps(user_info).encode('utf-8'))
                        })
                        
                        logger.info(f"âœ… çœŸå®ç™»å½•æŸ¥è¯¢ {i+1}/{test_count}: {response_time:.2f}ms "
                                  f"- {user_info.get('person_type')} {user_info.get('name', '')} "
                                  f"- å­—æ®µ: {field_count}/{len(expected_fields)}")
                    else:
                        results.append({
                            "response_time": response_time,
                            "status": "failed",
                            "error": f"HTTP {response.status}"
                        })
                        logger.warning(f"âš ï¸ çœŸå®ç™»å½•æŸ¥è¯¢å¤±è´¥ {i+1}: HTTP {response.status}")
                
            except Exception as e:
                results.append({
                    "response_time": 0,
                    "status": "error",
                    "error": str(e)
                })
                logger.error(f"âŒ çœŸå®ç™»å½•æŸ¥è¯¢å¼‚å¸¸ {i+1}: {e}")
            
            # æ§åˆ¶è¯·æ±‚é¢‘ç‡
            await asyncio.sleep(0.1)
        
        # ç»Ÿè®¡åˆ†æ
        successful_results = [r for r in results if r["status"] == "success"]
        
        if successful_results:
            response_times = [r["response_time"] for r in successful_results]
            
            stats = {
                "test_name": "çœŸå®ç™»å½•éªŒè¯æŸ¥è¯¢æ€§èƒ½æµ‹è¯•",
                "description": "å®Œå…¨æ¨¡æ‹Ÿç™»å½•æ—¶çš„4è¡¨JOINæŸ¥è¯¢(persons+colleges+majors+classes+departments)",
                "total_tests": len(results),
                "successful_tests": len(successful_results),
                "success_rate": f"{len(successful_results)/len(results)*100:.1f}%",
                "avg_response_time": f"{statistics.mean(response_times):.2f}ms",
                "min_response_time": f"{min(response_times):.2f}ms",
                "max_response_time": f"{max(response_times):.2f}ms",
                "median_response_time": f"{statistics.median(response_times):.2f}ms",
                "p95_response_time": f"{sorted(response_times)[int(len(response_times)*0.95)]:.2f}ms",
                "avg_fields_returned": f"{statistics.mean([r['fields_returned'] for r in successful_results]):.1f}",
                "avg_response_size": f"{statistics.mean([r['response_size'] for r in successful_results]):.0f} bytes",
                "join_completeness": {
                    "college_info_rate": f"{sum(1 for r in successful_results if r['has_college_info'])/len(successful_results)*100:.1f}%",
                    "major_info_rate": f"{sum(1 for r in successful_results if r['has_major_info'])/len(successful_results)*100:.1f}%",
                    "class_info_rate": f"{sum(1 for r in successful_results if r['has_class_info'])/len(successful_results)*100:.1f}%",
                    "department_info_rate": f"{sum(1 for r in successful_results if r['has_department_info'])/len(successful_results)*100:.1f}%"
                },
                "person_type_distribution": {
                    "student": sum(1 for r in successful_results if r.get('person_type') == 'student'),
                    "teacher": sum(1 for r in successful_results if r.get('person_type') == 'teacher'),
                    "admin": sum(1 for r in successful_results if r.get('person_type') == 'admin'),
                    "other": sum(1 for r in successful_results if r.get('person_type') not in ['student', 'teacher', 'admin'])
                }
            }
            
            # æ€§èƒ½è¯„çº§
            avg_time = statistics.mean(response_times)
            if avg_time < 100:
                performance_grade = "ğŸŸ¢ ä¼˜ç§€"
            elif avg_time < 300:
                performance_grade = "ğŸŸ¡ è‰¯å¥½"
            elif avg_time < 500:
                performance_grade = "ğŸŸ  ä¸€èˆ¬"
            else:
                performance_grade = "ğŸ”´ éœ€ä¼˜åŒ–"
            
            stats["performance_grade"] = performance_grade
            
            return stats
        else:
            return {"error": "æ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥äº†"}
    
    async def test_login_stress_performance(self, duration_seconds: int = 60) -> Dict[str, Any]:
        """ç™»å½•å‹åŠ›æµ‹è¯• - æ¨¡æ‹Ÿé«˜å¹¶å‘ç™»å½•åœºæ™¯"""
        logger.info(f"ğŸš€ å¼€å§‹ç™»å½•å‹åŠ›æµ‹è¯• - æŒç»­ {duration_seconds} ç§’...")
        
        # ç¡®ä¿æœ‰æµ‹è¯•è´¦å·
        if not self.test_accounts:
            await self.prepare_test_accounts()
        
        if not self.test_accounts:
            return {"error": "æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•è´¦å·"}
        
        results = []
        start_time = time.time()
        end_time = start_time + duration_seconds
        
        # å¹¶å‘ä»»åŠ¡åˆ—è¡¨
        tasks = []
        
        async def single_login_test():
            """å•æ¬¡ç™»å½•æµ‹è¯•"""
            account = random.choice(self.test_accounts)
            
            try:
                login_data = {
                    "login_id": account["login_id"],
                    "password": account["password"]
                }
                
                request_start = time.time()
                
                # é€šè¿‡èƒ¶æ°´å±‚è¿›è¡Œç™»å½•ï¼ˆæ›´çœŸå®çš„æµ‹è¯•ï¼‰
                async with self.session.post(
                    f"{self.backend_url}/api/v1/auth/login",
                    json=login_data
                ) as response:
                    request_end = time.time()
                    response_time = (request_end - request_start) * 1000
                    
                    result = {
                        "response_time": response_time,
                        "timestamp": request_start,
                        "account_type": account["person_type"],
                        "login_id": account["login_id"]
                    }
                    
                    if response.status == 200:
                        response_data = await response.json()
                        if response_data.get("status") == "success":
                            result["status"] = "success"
                            result["token_received"] = bool(response_data.get("data", {}).get("access_token"))
                            result["user_info_complete"] = bool(response_data.get("data", {}).get("user_info"))
                        else:
                            result["status"] = "failed"
                            result["error"] = response_data.get("message", "ç™»å½•å¤±è´¥")
                    else:
                        result["status"] = "failed"
                        result["error"] = f"HTTP {response.status}"
                    
                    return result
                    
            except Exception as e:
                return {
                    "response_time": 0,
                    "timestamp": time.time(),
                    "status": "error",
                    "error": str(e),
                    "account_type": account["person_type"],
                    "login_id": account["login_id"]
                }
        
        # æ‰§è¡Œå‹åŠ›æµ‹è¯•
        test_count = 0
        while time.time() < end_time:
            # æ¯ç§’å‘é€5-10ä¸ªå¹¶å‘ç™»å½•è¯·æ±‚
            batch_size = random.randint(5, 10)
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            batch_tasks = [single_login_test() for _ in range(batch_size)]
            
            # æ‰§è¡Œæ‰¹æ¬¡
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            # æ”¶é›†ç»“æœ
            for result in batch_results:
                if isinstance(result, dict):
                    results.append(result)
                    test_count += 1
            
            logger.info(f"ğŸ”„ å‹åŠ›æµ‹è¯•è¿›è¡Œä¸­... å·²å®Œæˆ {test_count} æ¬¡ç™»å½•å°è¯•")
            
            # æ§åˆ¶é¢‘ç‡ï¼Œé¿å…è¿‡è½½
            await asyncio.sleep(0.2)
        
        # ç»Ÿè®¡åˆ†æ
        successful_results = [r for r in results if r.get("status") == "success"]
        failed_results = [r for r in results if r.get("status") == "failed"]
        error_results = [r for r in results if r.get("status") == "error"]
        
        if results:
            response_times = [r["response_time"] for r in successful_results if r["response_time"] > 0]
            
            # æ—¶é—´åºåˆ—åˆ†æ
            time_series = []
            for i in range(0, duration_seconds, 10):  # æ¯10ç§’ç»Ÿè®¡ä¸€æ¬¡
                window_start = start_time + i
                window_end = window_start + 10
                window_results = [r for r in results 
                                if window_start <= r["timestamp"] < window_end]
                
                if window_results:
                    window_success = [r for r in window_results if r.get("status") == "success"]
                    time_series.append({
                        "time_window": f"{i}-{i+10}s",
                        "total_requests": len(window_results),
                        "successful_requests": len(window_success),
                        "success_rate": f"{len(window_success)/len(window_results)*100:.1f}%",
                        "avg_response_time": f"{statistics.mean([r['response_time'] for r in window_success]):.2f}ms" if window_success else "N/A"
                    })
            
            stats = {
                "test_name": "ç™»å½•å‹åŠ›æµ‹è¯•",
                "description": f"åœ¨ {duration_seconds} ç§’å†…è¿›è¡Œé«˜å¹¶å‘ç™»å½•æµ‹è¯•",
                "test_duration": f"{duration_seconds}s",
                "total_requests": len(results),
                "successful_requests": len(successful_results),
                "failed_requests": len(failed_results),
                "error_requests": len(error_results),
                "overall_success_rate": f"{len(successful_results)/len(results)*100:.1f}%",
                "requests_per_second": f"{len(results)/duration_seconds:.1f}",
                "successful_rps": f"{len(successful_results)/duration_seconds:.1f}",
                "performance_metrics": {
                    "avg_response_time": f"{statistics.mean(response_times):.2f}ms" if response_times else "N/A",
                    "min_response_time": f"{min(response_times):.2f}ms" if response_times else "N/A",
                    "max_response_time": f"{max(response_times):.2f}ms" if response_times else "N/A",
                    "median_response_time": f"{statistics.median(response_times):.2f}ms" if response_times else "N/A",
                    "p95_response_time": f"{sorted(response_times)[int(len(response_times)*0.95)]:.2f}ms" if response_times else "N/A",
                    "p99_response_time": f"{sorted(response_times)[int(len(response_times)*0.99)]:.2f}ms" if response_times else "N/A",
                },
                "account_type_performance": {},
                "time_series_analysis": time_series
            }
            
            # æŒ‰è´¦å·ç±»å‹åˆ†ææ€§èƒ½
            for account_type in ["student", "teacher", "admin"]:
                type_results = [r for r in successful_results if r.get("account_type") == account_type]
                if type_results:
                    type_times = [r["response_time"] for r in type_results]
                    stats["account_type_performance"][account_type] = {
                        "count": len(type_results),
                        "avg_response_time": f"{statistics.mean(type_times):.2f}ms",
                        "success_rate": f"{len(type_results)/len([r for r in results if r.get('account_type') == account_type])*100:.1f}%"
                    }
            
            # å‹åŠ›æµ‹è¯•è¯„çº§
            overall_success_rate = len(successful_results)/len(results)*100
            avg_response_time = statistics.mean(response_times) if response_times else float('inf')
            
            if overall_success_rate >= 95 and avg_response_time < 200:
                stress_grade = "ğŸŸ¢ ä¼˜ç§€ - ç³»ç»Ÿèƒ½å¾ˆå¥½åœ°å¤„ç†é«˜å¹¶å‘ç™»å½•"
            elif overall_success_rate >= 90 and avg_response_time < 500:
                stress_grade = "ğŸŸ¡ è‰¯å¥½ - ç³»ç»Ÿèƒ½è¾ƒå¥½åœ°å¤„ç†å¹¶å‘ç™»å½•"
            elif overall_success_rate >= 80:
                stress_grade = "ğŸŸ  ä¸€èˆ¬ - ç³»ç»Ÿåœ¨é«˜è´Ÿè½½ä¸‹æœ‰ä¸€å®šå‹åŠ›"
            else:
                stress_grade = "ğŸ”´ éœ€ä¼˜åŒ– - ç³»ç»Ÿéš¾ä»¥æ‰¿å—é«˜å¹¶å‘ç™»å½•"
            
            stats["stress_grade"] = stress_grade
            
            return stats
        else:
            return {"error": "å‹åŠ›æµ‹è¯•ä¸­æ²¡æœ‰è·å¾—ä»»ä½•ç»“æœ"}
    
    async def test_backend_api_comprehensive(self) -> Dict[str, Any]:
        """åç«¯APIç»¼åˆæ€§èƒ½æµ‹è¯•"""
        logger.info("ğŸ”¬ å¼€å§‹åç«¯APIç»¼åˆæ€§èƒ½æµ‹è¯•...")
        
        # ç¡®ä¿æœ‰è®¤è¯ä¿¡æ¯
        if not self.test_accounts:
            await self.prepare_test_accounts()
        
        # å‡†å¤‡è®¤è¯token
        auth_token = None
        if self.test_accounts:
            admin_account = next((acc for acc in self.test_accounts if acc["person_type"] == "admin"), None)
            if admin_account:
                try:
                    async with self.session.post(
                        f"{self.backend_url}/api/v1/auth/login",
                        json={"login_id": admin_account["login_id"], "password": admin_account["password"]}
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            auth_token = result.get("data", {}).get("access_token")
                except Exception as e:
                    logger.warning(f"è·å–è®¤è¯tokenå¤±è´¥: {e}")
        
        headers = {}
        if auth_token:
            headers["Authorization"] = f"Bearer {auth_token}"
        
        # APIæµ‹è¯•é…ç½® - ä½¿ç”¨çœŸå®çš„å­¦ç”ŸID
        test_student_id = "202100000001"  # ä½¿ç”¨çœŸå®çš„å­¦ç”Ÿå­¦å·
        api_tests = [
            {
                "name": "å…¬å‘Šåˆ—è¡¨",
                "url": f"{self.backend_url}/api/v1/announcements",
                "method": "GET",
                "params": {"page": 1, "size": 10}
            },
            {
                "name": "è¯¾è¡¨æŸ¥è¯¢",
                "url": f"{self.backend_url}/api/v1/schedule/student/{test_student_id}",
                "method": "GET",
                "params": {"semester": "2024-2025-1"}
            },
            {
                "name": "æˆç»©æŸ¥è¯¢", 
                "url": f"{self.backend_url}/api/v1/grades/student/{test_student_id}",
                "method": "GET",
                "params": {"semester": "2024-2025-1"}
            },
            {
                "name": "è€ƒè¯•åˆ—è¡¨",
                "url": f"{self.backend_url}/api/v1/exams",
                "method": "GET",
                "params": {"page": 1, "size": 10}
            },
            {
                "name": "è€ƒè¯•ç»Ÿè®¡",
                "url": f"{self.backend_url}/api/v1/exams/statistics",
                "method": "GET"
            }
        ]
        
        all_results = {}
        
        for api_test in api_tests:
            logger.info(f"ğŸ§ª æµ‹è¯• {api_test['name']} API...")
            
            test_results = []
            test_count = 20  # æ¯ä¸ªAPIæµ‹è¯•20æ¬¡
            
            for i in range(test_count):
                try:
                    start_time = time.time()
                    
                    async with self.session.request(
                        api_test["method"],
                        api_test["url"],
                        headers=headers,
                        params=api_test.get("params", {})
                    ) as response:
                        end_time = time.time()
                        response_time = (end_time - start_time) * 1000
                        
                        result = {
                            "response_time": response_time,
                            "status_code": response.status
                        }
                        
                        if response.status == 200:
                            response_data = await response.json()
                            result["status"] = "success"
                            result["data_size"] = len(json.dumps(response_data).encode('utf-8'))
                            
                            # æ£€æŸ¥å“åº”æ•°æ®è´¨é‡
                            if response_data.get("status") == "success":
                                data = response_data.get("data")
                                if isinstance(data, list):
                                    result["records_count"] = len(data)
                                elif isinstance(data, dict):
                                    result["records_count"] = len(data.get("records", []))
                        else:
                            result["status"] = "failed"
                        
                        test_results.append(result)
                        
                except Exception as e:
                    test_results.append({
                        "response_time": 0,
                        "status": "error",
                        "error": str(e)
                    })
                
                await asyncio.sleep(0.05)  # æ§åˆ¶é¢‘ç‡
            
            # ç»Ÿè®¡APIæµ‹è¯•ç»“æœ
            successful_results = [r for r in test_results if r.get("status") == "success"]
            
            if successful_results:
                response_times = [r["response_time"] for r in successful_results]
                
                api_stats = {
                    "total_tests": len(test_results),
                    "successful_tests": len(successful_results),
                    "success_rate": f"{len(successful_results)/len(test_results)*100:.1f}%",
                    "avg_response_time": f"{statistics.mean(response_times):.2f}ms",
                    "min_response_time": f"{min(response_times):.2f}ms",
                    "max_response_time": f"{max(response_times):.2f}ms",
                    "median_response_time": f"{statistics.median(response_times):.2f}ms"
                }
                
                if successful_results and "data_size" in successful_results[0]:
                    api_stats["avg_data_size"] = f"{statistics.mean([r['data_size'] for r in successful_results]):.0f} bytes"
                
                if successful_results and "records_count" in successful_results[0]:
                    api_stats["avg_records"] = f"{statistics.mean([r['records_count'] for r in successful_results]):.1f}"
                
                all_results[api_test["name"]] = api_stats
            else:
                all_results[api_test["name"]] = {"error": "æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥"}
        
        # ç»¼åˆè¯„çº§
        successful_apis = [name for name, stats in all_results.items() if "error" not in stats]
        if successful_apis:
            avg_response_times = []
            for name in successful_apis:
                try:
                    avg_time = float(all_results[name]["avg_response_time"].replace("ms", ""))
                    avg_response_times.append(avg_time)
                except:
                    pass
            
            if avg_response_times:
                overall_avg = statistics.mean(avg_response_times)
                if overall_avg < 200:
                    grade = "ğŸŸ¢ ä¼˜ç§€"
                elif overall_avg < 500:
                    grade = "ğŸŸ¡ è‰¯å¥½"
                else:
                    grade = "ğŸŸ  éœ€ä¼˜åŒ–"
            else:
                grade = "â“ æ— æ³•è¯„çº§"
        else:
            grade = "ğŸ”´ ç³»ç»Ÿå¼‚å¸¸"
        
        return {
            "test_name": "åç«¯APIç»¼åˆæ€§èƒ½æµ‹è¯•",
            "overall_grade": grade,
            "overall_avg_response_time": f"{statistics.mean(avg_response_times):.2f}ms" if avg_response_times else "N/A",
            "api_results": all_results,
            "successful_apis": f"{len(successful_apis)}/{len(api_tests)}"
        }

async def run_comprehensive_backend_test():
    """è¿è¡Œåç«¯APIç»¼åˆæ€§èƒ½æµ‹è¯•"""
    async with BackendAPIPerformanceTester() as tester:
        print("=" * 80)
        print("ğŸš€ åç«¯APIä¸“é¡¹æ€§èƒ½æµ‹è¯•")
        print("=" * 80)
        
        # å‡†å¤‡æµ‹è¯•è´¦å·
        print("\nğŸ“‹ å‡†å¤‡æµ‹è¯•è´¦å·...")
        accounts = await tester.prepare_test_accounts()
        if accounts:
            print(f"âœ… æˆåŠŸå‡†å¤‡ {len(accounts)} ä¸ªæµ‹è¯•è´¦å·")
            print(f"   - å­¦ç”Ÿè´¦å·: {len([a for a in accounts if a['person_type'] == 'student'])} ä¸ª")
            print(f"   - æ•™å¸ˆè´¦å·: {len([a for a in accounts if a['person_type'] == 'teacher'])} ä¸ª")
            print(f"   - ç®¡ç†å‘˜è´¦å·: {len([a for a in accounts if a['person_type'] == 'admin'])} ä¸ª")
        else:
            print("âŒ æ— æ³•è·å–æµ‹è¯•è´¦å·ï¼Œéƒ¨åˆ†æµ‹è¯•å¯èƒ½å¤±è´¥")
        
        # 1. çœŸå®ç™»å½•éªŒè¯æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
        print("\n" + "=" * 50)
        print("ğŸ“Š 1. çœŸå®ç™»å½•éªŒè¯æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        login_query_result = await tester.test_real_login_query_performance()
        
        if "error" not in login_query_result:
            print(f"ğŸ“ˆ æµ‹è¯•ç»“æœ: {login_query_result['performance_grade']}")
            print(f"   - å¹³å‡å“åº”æ—¶é—´: {login_query_result['avg_response_time']}")
            print(f"   - æˆåŠŸç‡: {login_query_result['success_rate']}")
            print(f"   - P95å“åº”æ—¶é—´: {login_query_result['p95_response_time']}")
            print(f"   - å¹³å‡è¿”å›å­—æ®µæ•°: {login_query_result['avg_fields_returned']}")
            print(f"   - å¹³å‡å“åº”å¤§å°: {login_query_result['avg_response_size']}")
            print(f"   - JOINå®Œæ•´æ€§:")
            for join_type, rate in login_query_result['join_completeness'].items():
                print(f"     Â· {join_type}: {rate}")
            print(f"   - äººå‘˜ç±»å‹åˆ†å¸ƒ: {login_query_result['person_type_distribution']}")
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {login_query_result['error']}")
        
        # 2. ç™»å½•å‹åŠ›æµ‹è¯•
        print("\n" + "=" * 50)
        print("ğŸš€ 2. ç™»å½•å‹åŠ›æµ‹è¯• (60ç§’)")
        print("=" * 50)
        stress_result = await tester.test_login_stress_performance(60)
        
        if "error" not in stress_result:
            print(f"ğŸ“ˆ å‹åŠ›æµ‹è¯•ç»“æœ: {stress_result['stress_grade']}")
            print(f"   - æ€»è¯·æ±‚æ•°: {stress_result['total_requests']}")
            print(f"   - æˆåŠŸè¯·æ±‚æ•°: {stress_result['successful_requests']}")
            print(f"   - æ•´ä½“æˆåŠŸç‡: {stress_result['overall_success_rate']}")
            print(f"   - æ¯ç§’è¯·æ±‚æ•°: {stress_result['requests_per_second']}")
            print(f"   - æˆåŠŸRPS: {stress_result['successful_rps']}")
            print(f"   - å¹³å‡å“åº”æ—¶é—´: {stress_result['performance_metrics']['avg_response_time']}")
            print(f"   - P95å“åº”æ—¶é—´: {stress_result['performance_metrics']['p95_response_time']}")
            print(f"   - P99å“åº”æ—¶é—´: {stress_result['performance_metrics']['p99_response_time']}")
            
            print("\n   ğŸ“Š åˆ†è´¦å·ç±»å‹æ€§èƒ½:")
            for acc_type, perf in stress_result['account_type_performance'].items():
                print(f"     Â· {acc_type}: {perf['avg_response_time']} (æˆåŠŸç‡: {perf['success_rate']})")
            
            print("\n   â±ï¸ æ—¶é—´åºåˆ—åˆ†æ:")
            for window in stress_result['time_series_analysis'][:6]:  # åªæ˜¾ç¤ºå‰6ä¸ªçª—å£
                print(f"     Â· {window['time_window']}: {window['successful_requests']}/{window['total_requests']} "
                      f"({window['success_rate']}) - {window['avg_response_time']}")
        else:
            print(f"âŒ å‹åŠ›æµ‹è¯•å¤±è´¥: {stress_result['error']}")
        
        # 3. åç«¯APIç»¼åˆæµ‹è¯•
        print("\n" + "=" * 50)
        print("ğŸ”¬ 3. åç«¯APIç»¼åˆæ€§èƒ½æµ‹è¯•")
        print("=" * 50)
        api_result = await tester.test_backend_api_comprehensive()
        
        print(f"ğŸ“ˆ ç»¼åˆæµ‹è¯•ç»“æœ: {api_result['overall_grade']}")
        print(f"   - æ•´ä½“å¹³å‡å“åº”æ—¶é—´: {api_result['overall_avg_response_time']}")
        print(f"   - æˆåŠŸAPIæ•°é‡: {api_result['successful_apis']}")
        
        print("\n   ğŸ“‹ å„APIè¯¦ç»†æ€§èƒ½:")
        for api_name, stats in api_result['api_results'].items():
            if "error" not in stats:
                print(f"     Â· {api_name}: {stats['avg_response_time']} "
                      f"(æˆåŠŸç‡: {stats['success_rate']}) "
                      f"[{stats.get('avg_records', 'N/A')}æ¡è®°å½•]")
            else:
                print(f"     Â· {api_name}: âŒ {stats['error']}")
        
        print("\n" + "=" * 80)
        print("ğŸ¯ æµ‹è¯•æ€»ç»“")
        print("=" * 80)
        print("âœ… åç«¯APIä¸“é¡¹æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š çœŸå®ç™»å½•æŸ¥è¯¢: {login_query_result.get('performance_grade', 'âŒ å¤±è´¥')}")
        print(f"ğŸš€ ç™»å½•å‹åŠ›æµ‹è¯•: {stress_result.get('stress_grade', 'âŒ å¤±è´¥')}")
        print(f"ğŸ”¬ APIç»¼åˆæµ‹è¯•: {api_result.get('overall_grade', 'âŒ å¤±è´¥')}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results = {
            "timestamp": datetime.now().isoformat(),
            "real_login_query_test": login_query_result,
            "login_stress_test": stress_result,
            "api_comprehensive_test": api_result
        }
        
        with open("backend_api_performance_results.json", "w", encoding="utf-8") as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: backend_api_performance_results.json")

if __name__ == "__main__":
    asyncio.run(run_comprehensive_backend_test()) 