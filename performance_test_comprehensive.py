#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SZTU-iCampus å…¨é¢æ€§èƒ½æµ‹è¯•è„šæœ¬
é¢å‘30åˆ†é’Ÿåä¸Šçº¿ç­”è¾©çš„æ€§èƒ½éªŒè¯

æµ‹è¯•æŒ‡æ ‡ï¼š
1. è¯·æ±‚è€—æ—¶ï¼ˆç«¯åˆ°ç«¯å“åº”æ—¶é—´ï¼‰
2. æ•°æ®åº“æŸ¥è¯¢è€—æ—¶ï¼ˆçº¯SQLæ‰§è¡Œæ—¶é—´ï¼‰
3. å‹åŠ›æµ‹è¯•ï¼ˆå¹¶å‘å¤„ç†èƒ½åŠ›ï¼‰

ä½œè€…ï¼šClaude Sonnet 4
æ—¥æœŸï¼š2025-06-25
"""

import asyncio
import time
import json
import sqlite3
import psutil
import threading
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from concurrent.futures import ThreadPoolExecutor
import logging
import statistics
import requests
import sys
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('performance_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""
    test_name: str
    total_time: float
    db_query_time: float = 0.0
    network_time: float = 0.0
    cache_hit: bool = False
    status_code: int = 0
    data_size: int = 0
    error_message: str = ""
    timestamp: str = ""

@dataclass
class StressTestResult:
    """å‹åŠ›æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    concurrent_users: int
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    min_response_time: float
    max_response_time: float
    qps: float
    cpu_usage: float
    memory_usage: float

class DatabaseQueryTester:
    """æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, db_path="data-service/sztu_campus.db"):
        self.db_path = db_path
        self.headers = {"X-API-Key": "sztu-data-service-key-2024"}
        self.data_service_url = "http://localhost:8001"
    
    def test_direct_sql_performance(self) -> Dict[str, float]:
        """ç›´æ¥æµ‹è¯•SQLæ‰§è¡Œæ€§èƒ½"""
        logger.info("ğŸ” å¼€å§‹æ•°æ®åº“ç›´æ¥æŸ¥è¯¢æ€§èƒ½æµ‹è¯•...")
        
        test_cases = {
            "ç®€å•é€‰æ‹©æŸ¥è¯¢": "SELECT * FROM persons WHERE person_type='student' LIMIT 10",
            "å¤æ‚JOINæŸ¥è¯¢": """
                SELECT p.name, c.college_name, m.major_name 
                FROM persons p 
                JOIN colleges c ON p.college_id = c.college_id 
                JOIN majors m ON p.major_id = m.major_id 
                WHERE p.person_type='student' LIMIT 10
            """,
            "èšåˆç»Ÿè®¡æŸ¥è¯¢": """
                SELECT college_id, COUNT(*) as student_count 
                FROM persons 
                WHERE person_type='student' AND is_deleted=0 
                GROUP BY college_id
            """,
            "å¤§è¡¨æŸ¥è¯¢": """
                SELECT e.*, ci.course_name 
                FROM enrollments e 
                JOIN course_instances ci ON e.course_instance_id = ci.instance_id 
                WHERE e.enrollment_status='completed' LIMIT 50
            """
        }
        
        results = {}
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            for test_name, sql in test_cases.items():
                times = []
                for i in range(3):  # æ¯ä¸ªæŸ¥è¯¢æ‰§è¡Œ3æ¬¡å–å¹³å‡å€¼
                    start_time = time.time()
                    cursor.execute(sql)
                    rows = cursor.fetchall()
                    end_time = time.time()
                    
                    query_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                    times.append(query_time)
                    
                    logger.info(f"  {test_name} ç¬¬{i+1}æ¬¡: {query_time:.2f}ms, è¿”å›{len(rows)}è¡Œ")
                
                avg_time = statistics.mean(times)
                results[test_name] = avg_time
                logger.info(f"âœ… {test_name} å¹³å‡è€—æ—¶: {avg_time:.2f}ms")
            
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
            
        return results
    
    def test_api_vs_direct_query(self) -> Dict[str, Dict[str, float]]:
        """å¯¹æ¯”APIè°ƒç”¨å’Œç›´æ¥æŸ¥è¯¢çš„æ€§èƒ½å·®å¼‚"""
        logger.info("ğŸ“Š å¼€å§‹API vs ç›´æ¥æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”...")
        
        # æµ‹è¯•æ¡ˆä¾‹ï¼šè·å–å­¦ç”ŸåŸºæœ¬ä¿¡æ¯
        student_id = "202100043213"
        
        # 1. ç›´æ¥æ•°æ®åº“æŸ¥è¯¢
        start_time = time.time()
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("""
                SELECT p.*, c.college_name, m.major_name 
                FROM persons p 
                LEFT JOIN colleges c ON p.college_id = c.college_id 
                LEFT JOIN majors m ON p.major_id = m.major_id 
                WHERE p.student_id = ?
            """, (student_id,))
            direct_result = cursor.fetchone()
            conn.close()
            direct_time = (time.time() - start_time) * 1000
            
        except Exception as e:
            logger.error(f"ç›´æ¥æŸ¥è¯¢å¤±è´¥: {e}")
            direct_time = 0
        
        # 2. data-service APIæŸ¥è¯¢
        start_time = time.time()
        try:
            response = requests.get(
                f"{self.data_service_url}/query/persons",
                params={
                    "filters": json.dumps({"student_id": student_id}),
                    "join_tables": "colleges,majors",
                    "limit": 1
                },
                headers=self.headers,
                timeout=10
            )
            api_time = (time.time() - start_time) * 1000
            api_success = response.status_code == 200
                
        except Exception as e:
            logger.error(f"APIæŸ¥è¯¢å¤±è´¥: {e}")
            api_time = 0
            api_success = False
        
        results = {
            "ç›´æ¥æ•°æ®åº“æŸ¥è¯¢": {"è€—æ—¶(ms)": direct_time, "æˆåŠŸ": True},
            "data-service API": {"è€—æ—¶(ms)": api_time, "æˆåŠŸ": api_success}
        }
        
        if direct_time > 0 and api_time > 0:
            overhead = api_time - direct_time
            overhead_percent = (overhead / direct_time) * 100
            results["APIå¼€é”€åˆ†æ"] = {
                "é¢å¤–è€—æ—¶(ms)": overhead,
                "å¼€é”€ç™¾åˆ†æ¯”(%)": overhead_percent
            }
            logger.info(f"ğŸ“ˆ APIè°ƒç”¨å¼€é”€: {overhead:.2f}ms ({overhead_percent:.1f}%)")
        
        return results

class EndToEndTester:
    """ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.backend_url = "http://127.0.0.1:8000"
        self.test_user = {"login_id": "202100043213", "password": "123456"}
        self.auth_token = None
        self.metrics: List[PerformanceMetrics] = []
    
    def authenticate(self) -> bool:
        """ç”¨æˆ·è®¤è¯"""
        try:
            start_time = time.time()
            response = requests.post(
                f"{self.backend_url}/api/v1/auth/login",
                json=self.test_user,
                timeout=30
            )
            total_time = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                data = response.json()
                self.auth_token = data.get("data", {}).get("access_token")
                
                # è®°å½•ç™»å½•æ€§èƒ½
                metric = PerformanceMetrics(
                    test_name="ç”¨æˆ·ç™»å½•",
                    total_time=total_time,
                    status_code=response.status_code,
                    data_size=len(response.content),
                    timestamp=datetime.now().isoformat()
                )
                self.metrics.append(metric)
                
                logger.info(f"âœ… ç™»å½•æˆåŠŸ: {total_time:.2f}ms")
                return True
            else:
                logger.error(f"âŒ ç™»å½•å¤±è´¥: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ç™»å½•å¼‚å¸¸: {e}")
            return False
    
    def test_core_apis(self) -> List[PerformanceMetrics]:
        """æµ‹è¯•æ ¸å¿ƒAPIæ€§èƒ½"""
        if not self.auth_token:
            self.authenticate()
        
        headers = {"Authorization": f"Bearer {self.auth_token}"}
        
        # æ ¸å¿ƒAPIæµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {
                "name": "è¯¾è¡¨æŸ¥è¯¢",
                "url": f"{self.backend_url}/api/v1/schedule/",
                "params": {"semester": "2024-2025-1"},
                "critical": True  # å…³é”®ä¸šåŠ¡
            },
            {
                "name": "æˆç»©æŸ¥è¯¢", 
                "url": f"{self.backend_url}/api/v1/grades",
                "params": {"semester": "2024-2025-1"},
                "critical": True
            },
            {
                "name": "å…¬å‘Šåˆ—è¡¨",
                "url": f"{self.backend_url}/api/v1/announcements",
                "params": {"page": 1, "size": 10},
                "critical": False
            },
            {
                "name": "è€ƒè¯•åˆ—è¡¨",
                "url": f"{self.backend_url}/api/v1/exams",
                "params": {"limit": 10},
                "critical": False
            }
        ]
        
        logger.info("ğŸš€ å¼€å§‹æ ¸å¿ƒAPIæ€§èƒ½æµ‹è¯•...")
        
        for test_case in test_cases:
            # æ¯ä¸ªAPIæµ‹è¯•3æ¬¡å–å¹³å‡å€¼
            times = []
            success_count = 0
            
            for i in range(3):
                start_time = time.time()
                try:
                    response = requests.get(
                        test_case["url"],
                        params=test_case["params"],
                        headers=headers,
                        timeout=30
                    )
                    total_time = (time.time() - start_time) * 1000
                    times.append(total_time)
                    
                    if response.status_code == 200:
                        success_count += 1
                        
                    # ç¬¬ä¸€æ¬¡è¯·æ±‚è®°å½•è¯¦ç»†ä¿¡æ¯
                    if i == 0:
                        metric = PerformanceMetrics(
                            test_name=test_case["name"],
                            total_time=total_time,
                            status_code=response.status_code,
                            data_size=len(response.content),
                            timestamp=datetime.now().isoformat()
                        )
                        self.metrics.append(metric)
                    
                    logger.info(f"  {test_case['name']} ç¬¬{i+1}æ¬¡: {total_time:.2f}ms")
                    
                except Exception as e:
                    logger.error(f"  {test_case['name']} ç¬¬{i+1}æ¬¡å¤±è´¥: {e}")
                    times.append(0)
            
            # è®¡ç®—å¹³å‡æ€§èƒ½
            valid_times = [t for t in times if t > 0]
            if valid_times:
                avg_time = statistics.mean(valid_times)
                success_rate = success_count / 3 * 100
                
                # æ€§èƒ½è¯„ä¼°
                performance_level = self._evaluate_performance(avg_time, test_case["critical"])
                
                logger.info(f"ğŸ“Š {test_case['name']} æ±‡æ€»:")
                logger.info(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f}ms")
                logger.info(f"   æˆåŠŸç‡: {success_rate:.1f}%")
                logger.info(f"   æ€§èƒ½ç­‰çº§: {performance_level}")
                
        return self.metrics
    
    def test_cache_effectiveness(self) -> Dict[str, Any]:
        """æµ‹è¯•ç¼“å­˜æ•ˆæœ"""
        logger.info("ğŸ”„ æµ‹è¯•ç¼“å­˜æ•ˆæœ...")
        
        if not self.auth_token:
            self.authenticate()
        
        headers = {"Authorization": f"Bearer {self.auth_token}"}
        
        # æ¸…ç©ºç¼“å­˜ï¼ˆå¦‚æœæœ‰ç›¸å…³APIï¼‰
        try:
            requests.delete(f"{self.backend_url}/api/v1/cache/clear", headers=headers)
        except:
            pass  # å¦‚æœæ²¡æœ‰æ¸…ç¼“å­˜APIä¹Ÿæ²¡å…³ç³»
        
        # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        start_time = time.time()
        response1 = requests.get(
            f"{self.backend_url}/api/v1/schedule/",
            params={"semester": "2024-2025-1"},
            headers=headers,
            timeout=30
        )
        cache_miss_time = (time.time() - start_time) * 1000
        
        # ç­‰å¾…1ç§’å†æ¬¡è¯·æ±‚ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰
        time.sleep(1)
        start_time = time.time()
        response2 = requests.get(
            f"{self.backend_url}/api/v1/schedule/",
            params={"semester": "2024-2025-1"},
            headers=headers,
            timeout=30
        )
        cache_hit_time = (time.time() - start_time) * 1000
        
        # åˆ†æç¼“å­˜æ•ˆæœ
        improvement = (cache_miss_time - cache_hit_time) / cache_miss_time * 100
        cache_effective = improvement > 10  # è¶…è¿‡10%æ”¹å–„è®¤ä¸ºç¼“å­˜æœ‰æ•ˆ
        
        cache_result = {
            "ç¼“å­˜æœªå‘½ä¸­æ—¶é—´(ms)": cache_miss_time,
            "ç¼“å­˜å‘½ä¸­æ—¶é—´(ms)": cache_hit_time,
            "æ€§èƒ½æå‡(%)": improvement,
            "ç¼“å­˜æœ‰æ•ˆ": cache_effective,
            "æå‡å€æ•°": cache_miss_time / cache_hit_time if cache_hit_time > 0 else 0
        }
        
        logger.info(f"ğŸ“ˆ ç¼“å­˜æ•ˆæœåˆ†æ:")
        logger.info(f"   ç¼“å­˜æœªå‘½ä¸­: {cache_miss_time:.2f}ms")
        logger.info(f"   ç¼“å­˜å‘½ä¸­: {cache_hit_time:.2f}ms")
        logger.info(f"   æ€§èƒ½æå‡: {improvement:.1f}%")
        logger.info(f"   ç¼“å­˜çŠ¶æ€: {'âœ… æœ‰æ•ˆ' if cache_effective else 'âŒ æ— æ•ˆ'}")
        
        return cache_result
    
    def _evaluate_performance(self, response_time: float, is_critical: bool) -> str:
        """è¯„ä¼°æ€§èƒ½ç­‰çº§"""
        if is_critical:
            # å…³é”®ä¸šåŠ¡æ›´ä¸¥æ ¼çš„æ ‡å‡†
            if response_time < 500:
                return "ğŸŸ¢ ä¼˜ç§€"
            elif response_time < 1000:
                return "ğŸŸ¡ è‰¯å¥½"
            elif response_time < 2000:
                return "ğŸŸ  ä¸€èˆ¬"
            else:
                return "ğŸ”´ éœ€ä¼˜åŒ–"
        else:
            # éå…³é”®ä¸šåŠ¡æ ‡å‡†
            if response_time < 1000:
                return "ğŸŸ¢ ä¼˜ç§€"
            elif response_time < 2000:
                return "ğŸŸ¡ è‰¯å¥½" 
            elif response_time < 3000:
                return "ğŸŸ  ä¸€èˆ¬"
            else:
                return "ğŸ”´ éœ€ä¼˜åŒ–"

class StressTester:
    """å‹åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.backend_url = "http://127.0.0.1:8000"
        self.test_users = [
            {"login_id": "202100043213", "password": "123456"},
            {"login_id": "202100008036", "password": "123456"},
            # å¯ä»¥æ·»åŠ æ›´å¤šæµ‹è¯•ç”¨æˆ·
        ]
        self.results: List[StressTestResult] = []
    
    def concurrent_login_test(self, concurrent_users: int = 20) -> StressTestResult:
        """å¹¶å‘ç™»å½•æµ‹è¯•"""
        logger.info(f"ğŸ”¥ å¼€å§‹å¹¶å‘ç™»å½•æµ‹è¯• - {concurrent_users}ä¸ªå¹¶å‘ç”¨æˆ·...")
        
        start_time = time.time()
        
        # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨
        initial_cpu = psutil.cpu_percent()
        initial_memory = psutil.virtual_memory().percent
        
        def single_login_test(user_index: int) -> Dict[str, Any]:
            """å•ä¸ªç”¨æˆ·ç™»å½•æµ‹è¯•"""
            user = self.test_users[user_index % len(self.test_users)]
            
            try:
                request_start = time.time()
                response = requests.post(
                    f"{self.backend_url}/api/v1/auth/login",
                    json=user,
                    timeout=30
                )
                request_time = (time.time() - request_start) * 1000
                
                return {
                    "success": response.status_code == 200,
                    "response_time": request_time,
                    "status_code": response.status_code
                }
            except Exception as e:
                return {
                    "success": False,
                    "response_time": 0,
                    "error": str(e)
                }
        
        # å¹¶å‘æ‰§è¡Œç™»å½•æµ‹è¯•
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(single_login_test, i) for i in range(concurrent_users)]
            test_results = [future.result() for future in futures]
        
        total_time = time.time() - start_time
        
        # è®°å½•ç³»ç»Ÿèµ„æºä½¿ç”¨
        final_cpu = psutil.cpu_percent()
        final_memory = psutil.virtual_memory().percent
        
        # ç»Ÿè®¡ç»“æœ
        successful = [r for r in test_results if r["success"]]
        failed = [r for r in test_results if not r["success"]]
        response_times = [r["response_time"] for r in successful if r["response_time"] > 0]
        
        result = StressTestResult(
            concurrent_users=concurrent_users,
            total_requests=len(test_results),
            successful_requests=len(successful),
            failed_requests=len(failed),
            avg_response_time=statistics.mean(response_times) if response_times else 0,
            min_response_time=min(response_times) if response_times else 0,
            max_response_time=max(response_times) if response_times else 0,
            qps=len(successful) / total_time if total_time > 0 else 0,
            cpu_usage=final_cpu,
            memory_usage=final_memory
        )
        
        self.results.append(result)
        
        logger.info(f"ğŸ“Š å¹¶å‘ç™»å½•æµ‹è¯•ç»“æœ:")
        logger.info(f"   å¹¶å‘ç”¨æˆ·æ•°: {concurrent_users}")
        logger.info(f"   æˆåŠŸè¯·æ±‚: {len(successful)}/{len(test_results)}")
        logger.info(f"   å¹³å‡å“åº”æ—¶é—´: {result.avg_response_time:.2f}ms")
        logger.info(f"   QPS: {result.qps:.2f}")
        logger.info(f"   CPUä½¿ç”¨ç‡: {result.cpu_usage:.1f}%")
        logger.info(f"   å†…å­˜ä½¿ç”¨ç‡: {result.memory_usage:.1f}%")
        
        return result

def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    logger.info("ğŸš€ å¼€å§‹SZTU-iCampuså…¨é¢æ€§èƒ½æµ‹è¯•...")
    logger.info("â° æµ‹è¯•æ—¶é—´é¢„è®¡ï¼š15-20åˆ†é’Ÿ")
    
    try:
        # é˜¶æ®µä¸€ï¼šæ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯• (5åˆ†é’Ÿ)
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š é˜¶æ®µä¸€ï¼šæ•°æ®åº“æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
        logger.info("="*60)
        
        db_tester = DatabaseQueryTester()
        
        # ç›´æ¥SQLæ€§èƒ½æµ‹è¯•
        sql_results = db_tester.test_direct_sql_performance()
        
        # API vs ç›´æ¥æŸ¥è¯¢å¯¹æ¯”
        api_vs_direct = db_tester.test_api_vs_direct_query()
        
        # é˜¶æ®µäºŒï¼šç«¯åˆ°ç«¯APIæ€§èƒ½æµ‹è¯• (10åˆ†é’Ÿ)
        logger.info("\n" + "="*60)
        logger.info("ğŸ”„ é˜¶æ®µäºŒï¼šç«¯åˆ°ç«¯APIæ€§èƒ½æµ‹è¯•")
        logger.info("="*60)
        
        e2e_tester = EndToEndTester()
        
        # æ ¸å¿ƒAPIæ€§èƒ½æµ‹è¯•
        api_metrics = e2e_tester.test_core_apis()
        
        # ç¼“å­˜æ•ˆæœæµ‹è¯•
        cache_results = e2e_tester.test_cache_effectiveness()
        
        # é˜¶æ®µä¸‰ï¼šå‹åŠ›æµ‹è¯• (5åˆ†é’Ÿ)
        logger.info("\n" + "="*60)
        logger.info("ğŸ”¥ é˜¶æ®µä¸‰ï¼šç³»ç»Ÿå‹åŠ›æµ‹è¯•")
        logger.info("="*60)
        
        stress_tester = StressTester()
        
        # å¹¶å‘ç™»å½•æµ‹è¯•
        for concurrent in [10, 20]:
            result = stress_tester.concurrent_login_test(concurrent)
            time.sleep(2)  # è®©ç³»ç»Ÿæ¢å¤
        
        # è¾“å‡ºå…³é”®ç»“è®º
        logger.info("\n" + "ğŸ¯ æµ‹è¯•ç»“è®ºæ‘˜è¦:")
        
        # åˆ†æAPIæ€§èƒ½
        critical_apis = [m for m in api_metrics if m.test_name in ["è¯¾è¡¨æŸ¥è¯¢", "ç”¨æˆ·ç™»å½•"]]
        if critical_apis:
            avg_critical_time = statistics.mean([m.total_time for m in critical_apis])
            logger.info(f"å…³é”®APIå¹³å‡å“åº”æ—¶é—´: {avg_critical_time:.2f}ms")
            
            if avg_critical_time < 1000:
                logger.info("ç³»ç»ŸçŠ¶æ€: ğŸŸ¢ ä¼˜ç§€ - å·²å‡†å¤‡å¥½ç­”è¾©æ¼”ç¤º")
            elif avg_critical_time < 2000:
                logger.info("ç³»ç»ŸçŠ¶æ€: ğŸŸ¡ è‰¯å¥½ - å¯ä»¥è¿›è¡Œç­”è¾©")
            else:
                logger.info("ç³»ç»ŸçŠ¶æ€: ğŸ”´ éœ€ä¼˜åŒ– - å»ºè®®ä¼˜åŒ–åå†ç­”è¾©")
        
        # åˆ†æç¼“å­˜æ•ˆæœ
        if cache_results and cache_results.get("ç¼“å­˜æœ‰æ•ˆ"):
            improvement = cache_results.get("æ€§èƒ½æå‡(%)", 0)
            logger.info(f"ç¼“å­˜æ€§èƒ½æå‡: {improvement:.1f}%")
        
        # åˆ†æå‹åŠ›æµ‹è¯•
        if stress_tester.results:
            max_qps = max([s.qps for s in stress_tester.results])
            logger.info(f"æœ€å¤§QPS: {max_qps:.2f}")
        
        logger.info("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        logger.info("ğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° performance_test.log")
        
        # ç­”è¾©å»ºè®®
        logger.info("\n" + "ğŸ¤ ç­”è¾©æ¼”ç¤ºå»ºè®®:")
        logger.info("1. ğŸ—ï¸ å±•ç¤ºä¸‰å±‚æ¶æ„è®¾è®¡ï¼ˆå‰ç«¯-èƒ¶æ°´å±‚-æ•°æ®åº“åˆ†ç¦»ï¼‰")
        logger.info("2. âš¡ å¼ºè°ƒæ€§èƒ½ä¼˜åŒ–æˆæœï¼ˆN+1æŸ¥è¯¢â†’æ‰¹é‡æŸ¥è¯¢ï¼Œ84%æå‡ï¼‰")
        logger.info("3. ğŸ”„ æ¼”ç¤ºç¼“å­˜æœºåˆ¶å’Œæµå¼æ¨é€åŠŸèƒ½")
        logger.info("4. ğŸ“Š å±•ç¤ºæœ¬æ¬¡æ€§èƒ½æµ‹è¯•ç»“æœä½œä¸ºæŠ€æœ¯å®åŠ›è¯æ˜")
        logger.info("5. ğŸ¯ çªå‡ºé¡¹ç›®æ ¸å¿ƒäº®ç‚¹ï¼šå®æ—¶æ¨é€+æ€§èƒ½ä¼˜åŒ–+åˆ†ç¦»æ¶æ„")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ
    logger.info("ğŸ”§ æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ...")
    logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
    logger.info(f"CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()}")
    logger.info(f"å†…å­˜æ€»é‡: {psutil.virtual_memory().total // (1024**3)}GB")
    
    # è¿è¡Œæµ‹è¯•
    main() 
